---
title: "Machine Learning Project"
author: "John Lee"
date: "September 25, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r,echo=FALSE}
load("models.RData")
```

## Getting and Cleaning Data
load packages.
```{r,message=FALSE}
library(caret)
sessionInfo()
```


```{r download,eval=FALSE}
urltrain <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
urltest <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if (!dir.exists("Data")) {
    dir.create("Data")
}
download.file(urltrain,destfile = "Data/pml_train.csv")
download.file(urltest,destfile = "Data/pml_test.csv")
```  
After downloading the files, we can read the data.
```{r, cache=TRUE}
training <- read.csv("Data/pml_train.csv",header = TRUE,row.names = 1,na.strings = c("NA","NaN","","#DIV/0!"))
testing <- read.csv("Data/pml_test.csv",header = TRUE,row.names = 1,na.strings = c("NA","NaN","","#DIV/0!"))
```
## Exploratory Data Analysis

```{r}
dim(training);dim(testing)
names(training)
```
We've got about 20000 observations with 158 dimensions and one output--"classe" to map. However, because the origin website that describes these variables are not accessable, so I just guess that the first six variables can't be used to predict.
```{r, cache=TRUE}
meanna <- apply(training,2,function(x) mean(is.na(x)))
hist(meanna,breaks=100,main="NA proportion of the training data")
```  

So there are too many columns in the training dataset that are completely missing. We won't like using these variables to make predictions.  

Let's choose the variables we can use happily.
```{r}
columns <- meanna==0
columns[1:6] <- FALSE
training2 <- training[,columns]
testing2 <- testing[,columns]
mean(is.na(testing2))
```  
It turns out that our filter also works for test data.

```{r, cache=TRUE}
cor(training2[,1:52],unclass(training2[,53]))
```  
We can see some of the variables are relatively correlated with the `classe`, such as `magnet_arm_x` and `pitch_forearm`.

## Fitting the Model
Here we have a relative small size of data, and we face a classification problem. We've got 5 classes of people's manner in which they did the exercise. I would say that a using a neural network with a softmax output layer will achieve a very high accuracy, but it require too much computation. Using decision tree seems to be very natural and we can choose **bagging** or **random forest** or **boosting**. Here I guess **random forest** is better because it was generated from multiple trees, which can be very accurate, although it requires more computation. But Let's try different models to test.

Let's first split our training dataset into train dataset and test dataset.  
Here it seems we don't need to normalize our data(the absolute values matters).
```{r}
set.seed(2333)
inTrain <- createDataPartition(training2$classe,p=0.8,list = FALSE)
ttraining <- training2[inTrain,]
ttesting <- training2[-inTrain,]
```  
Here I will consider boosting with trees(gbm) and random forest(rf), both of which are generated by trees.
```{r, cache=TRUE,eval=FALSE}
mdlgbm <- train(classe~.,method="gbm",data = ttraining,verbose=FALSE)
```  
This takes about 20minutes, Then we try random forest.
```{r, cache=TRUE,eval=FALSE}
mdlrf <- train(classe~.,method="rf",data = ttraining,verbose=FALSE)
```  

Random forest takes about 50 minutes, Then we try Linear Discriminant Analysis, which assumes the predictors are multivariate Gaussian with same covariances(here it seems not realistic), and Naive Bayes, which assumes independence between preditors.
```{r,eval=FALSE}
mdllda <- train(classe~.,method="lda",data = ttraining,verbose=FALSE)
mdlnb <- train(classe~.,method="nb",data = ttraining,verbose=FALSE)
``` 
Linear Discriminant Analysis takes only 7 seconds, and Naive Bayes takes about 30 minutes.
## Model selection
Let evaluate the accuracy of each models
```{r,cache=TRUE,eval=FALSE}
models <- list(mdlgbm,mdlrf,mdllda,mdlnb)
m <- matrix(nrow = 4,ncol = 2)
rownames(m) <- c("gbm","rf","lda","nb")
colnames(m) <- c("training error","testing error")
for (i in 1:4) {
    actrain <- mean(predict(models[[i]],ttraining)==ttraining$classe)
    actest <- mean(predict(models[[i]],ttesting)==ttesting$classe)
    m[i,] <- c(actrain,actest)
}
```  
Now Let's print the accuracy table:
```{r}
m
```  
It turns out that the random forest works really well.
```{r}
confusionMatrix(predict(mdlrf,ttesting),ttesting$classe)
```  
The random forest works almost perfect in all cases except for classe D.  

Let's predict the remaining 20 samples.
```{r}
predict(mdlrf,testing2)
```
## Conclusion
In this project we build a classifier using random forest to predict the people's manner in which they did the exercise. Here the algorithm works really well, which can be used to predict the other 20 examples. Compared to random forest, boosting with trees has a relatively smaller accuracy but faster computation. Because of the incorrect assumption, Linear Discriminant Analysis works really fast but is not accurate, naive bayes here is both slow and inaccurate. Concretely, if there's enough time, we can consider random forest because it's accurate and do not require sophisticated assumptions.